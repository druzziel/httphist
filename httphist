#!/usr/bin/python

import datetime, sys, math, operator


TIME_FORMAT = '%d/%b/%Y:%H:%M'
ONE_MINUTE = datetime.timedelta( minutes = 1 )
SCALE_FACTOR = 1
COLUMNS = 60


##########################################################
# functions for dealing with our dictionary.
# The dictionary has a key for every minute between
# the start and end of the log.  The value for each
# key is the number of requests that were logged in 
# that minute.
##########################################################

def getDictionary( startTime, endTime ):
    i = startTime
    emptyDictionary = {}
    while i <= endTime:
        emptyDictionary[i] = 0
        i += ONE_MINUTE
    return emptyDictionary 

def printDictionary( dictionary, autoscale=True ):
    longestLine = max(dictionary.iteritems(), key=operator.itemgetter(1))[1]
    autoscale_factor = float(COLUMNS) / longestLine
    if ( autoscale_factor >= 1 ) or ( not autoscale ):
        autoscale_factor = 1
    dkeys = dictionary.keys()
    dkeys.sort()
    for dkey in dkeys:
        count = dictionary[dkey]
        histoLine = getHistogramLine( int( count * autoscale_factor ) )
        print "{0} {1:>4} {2}".format(dkey, count, histoLine)

def getHistogramLine( lineCount ):
    # return a string of hash marks
    # the number of hash marks is lineCount / scaleFactor,
    # where scaleFactor defaults to 1.  Increasing scaleFactor reduces
    # the scale of the histogram
    length = math.ceil( float(lineCount) / float(SCALE_FACTOR) )
    return '#' * int(length)

def populateDictionary( logfile, dictionary ):
    logfile.seek(0)
    for line in logfile:
        timestamp = extractTime( line )
        dictionary[timestamp] += 1

#############################
# End Dictionary Functions
#############################

#############################
# Time-handling functions
#############################

def convertTimestamp(apache_timestamp):
    """convert an Apache datetime string to a Python datetime object"""
    try:
        time_obj = datetime.datetime.strptime( apache_timestamp, TIME_FORMAT )
    except:
        raise TypeError, "%s is not a timestamp I recognize." % apache_timestamp
    return time_obj

def extractTime( input_line ):
    """Takes a line from the input file and returns a time object based on that line's timestamp"""
    bits = input_line.split()
    for field in bits:
        apache_timestamp = field[1:-3]
        try:
            return convertTimestamp( apache_timestamp )
        except:
            pass
    raise ValueError, "Unreachable line reached - no timestamp found in input line {}".format( input_line )

##############################
# End Time-handling functions
##############################



#############################
# Main loop helper functions
#############################

def openLog( logFileName ):
    try:
        fp = open( logFileName )
    except:
        print "Sorry, I couldn't open {0}.  Exiting.".format( logFileName )
        sys.exit()
    return fp

def getLogStartandStopTimes( fp ):
    firstline = fp.readline()
    for line in fp:
        pass
    lastline = line
    startTime = extractTime( firstline )
    endTime = extractTime( lastline )
    return startTime, endTime

#################################
# End Main loop helper functions
#################################

def usage():
    print """usage: %s <logfile> [ scale_factor ]
Where <logfile> is an Apache combined log, and
scale_factor can be used to shorten output lines.""" % sys.argv[0]

if __name__ == "__main__":

    import argparse
    parser = argparse.ArgumentParser()

    parser.add_argument("logfile",
        help="Apache/NCSA log file to analyze",
        type=str)

    parser.add_argument("-s", "--scaling_factor", 
        help="reduce the length of histogram lines by dividing by this value",
        type=int)

    parser.add_argument("-a", "--autoscale",
        help="automatically reduce histogram length to fit screen",
        action="store_true")

    parser.add_argument("-c", "--columns", "--cols",
        help="specify maximum column width",
        type=int)

    args = parser.parse_args()
    if args.scaling_factor:
        SCALE_FACTOR = args.scaling_factor
    if args.columns:
        COLUMNS = args.columns
    
    fp = openLog( args.logfile )

    # obtain first and last lines so we know start and end times
    startTime, endTime = getLogStartandStopTimes( fp )

    # create a dictionary to hold our data
    myDictionary = getDictionary(startTime, endTime)

    # fill 'er up
    populateDictionary( fp, myDictionary )
    fp.close()  # it's polite.

    # show us what you got
    autoscale = args.autoscale 
    printDictionary( myDictionary, autoscale=autoscale )
