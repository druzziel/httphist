#!/usr/bin/python

# Copyright 2019 W. David W. Roth  (uzziel@gmail.com)
# This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.


import datetime, sys, math, operator


TIME_FORMAT = '%d/%b/%Y:%H:%M'
ONE_MINUTE = datetime.timedelta( minutes = 1 )
SCALE_FACTOR = 1
COLUMNS = 60


##########################################################
# functions for dealing with our dictionary.
# The dictionary has a key for every minute between
# the start and end of the log.  The value for each
# key is the number of requests that were logged in 
# that minute.
##########################################################

def get_dictionary( startTime, endTime ):
    i = startTime
    empty_dictionary = {}
    while i <= endTime:
        empty_dictionary[i] = 0
        i += ONE_MINUTE
    return empty_dictionary 

def print_dictionary( dictionary, autoscale=False ):
    longestLine = max(dictionary.iteritems(), key=operator.itemgetter(1))[1]
    autoscale_factor = float(COLUMNS) / longestLine
    if ( autoscale_factor >= 1 ) or ( not autoscale ):
        autoscale_factor = 1
    dkeys = dictionary.keys()
    dkeys.sort()
    for dkey in dkeys:
        count = dictionary[dkey]
        histoLine = get_histogram_line( int( count * autoscale_factor ) )
        print "{0} {1:>4} {2}".format(dkey, count, histoLine)

def get_histogram_line( lineCount ):
    # return a string of hash marks
    # the number of hash marks is lineCount / scaleFactor,
    # where scaleFactor defaults to 1.  Increasing scaleFactor reduces
    # the scale of the histogram
    length = math.ceil( float(lineCount) / float(SCALE_FACTOR) )
    return '#' * int(length)

def populate_dictionary( logfile, dictionary ):
    logfile.seek(0)
    for line in logfile:
        try:   # throw away any line without a timestamp
            timestamp = extract_time( line )
            dictionary[timestamp] += 1
        except:
            next

#############################
# End Dictionary Functions
#############################

#############################
# Time-handling functions
#############################

def convert_timestamp(apache_timestamp):
    """convert an Apache datetime string to a Python datetime object"""
    try:
        time_obj = datetime.datetime.strptime( apache_timestamp, TIME_FORMAT )
    except:
        raise TypeError, "%s is not a timestamp I recognize." % apache_timestamp
    return time_obj

def extract_time( input_line ):
    """Takes a line from the input file and returns a time object based on that line's timestamp"""
    bits = input_line.split()
    for field in bits:
        apache_timestamp = field[1:-3]
        try:
            return convert_timestamp( apache_timestamp )
        except:
            pass
    raise ValueError, "Unreachable line reached - no timestamp found in input line {}".format( input_line )

##############################
# End Time-handling functions
##############################



#############################
# Main loop helper functions
#############################

def openLog( logFileName ):
    try:
        fp = open( logFileName )
    except:
        print "Sorry, I couldn't open {0}.  Exiting.".format( logFileName )
        sys.exit()
    return fp

def get_log_start_and_stop_times( fp ):
    firstline = fp.readline()
    for line in fp:
        pass
    lastline = line
    startTime = extract_time( firstline )
    endTime = extract_time( lastline )
    return startTime, endTime

#################################
# End Main loop helper functions
#################################

def usage():
    print """usage: %s <logfile> [ scale_factor ]
Where <logfile> is an Apache combined log, and
scale_factor can be used to shorten output lines.""" % sys.argv[0]

if __name__ == "__main__":

    import argparse
    parser = argparse.ArgumentParser(description="generate a histogram from an Apache/NCSA log file showing per-minute usage")

    parser.add_argument("logfile",
        help="Apache/NCSA log file to analyze",
        type=str)

    parser.add_argument("-s", "--scaling_factor", 
        help="reduce the length of histogram lines by dividing by this value",
        type=int)

    parser.add_argument("-a", "--autoscale",
        help="automatically reduce histogram length to fit screen",
        action="store_true")

    parser.add_argument("-c", "--columns", "--cols",
        help="specify maximum column width",
        type=int)

    args = parser.parse_args()
    if args.scaling_factor:
        SCALE_FACTOR = args.scaling_factor
    if args.columns:
        COLUMNS = args.columns
    
    fp = openLog( args.logfile )

    # obtain first and last lines so we know start and end times
    startTime, endTime = get_log_start_and_stop_times( fp )

    # create a dictionary to hold our data
    myDictionary = get_dictionary(startTime, endTime)

    # fill 'er up
    populate_dictionary( fp, myDictionary )
    fp.close()  # it's polite.

    # show us what you got
    autoscale = args.autoscale 
    print_dictionary( myDictionary, autoscale=autoscale )
